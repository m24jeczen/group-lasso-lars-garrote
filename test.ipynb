{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9455beb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Comparison:\n",
      "          Method       MSE\n",
      "0     OLS (Full)  0.485308\n",
      "1     Group LARS  2.301095\n",
      "2  Group Garrote  1.548278\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1. DATA GENERATION â€” MODEL I\n",
    "np.random.seed(0)\n",
    "n_samples = 50\n",
    "n_factors = 15\n",
    "rho = 0.5\n",
    "\n",
    "# Covariance matrix for correlated normal variables\n",
    "cov_matrix = rho ** np.abs(np.subtract.outer(np.arange(n_factors), np.arange(n_factors)))\n",
    "Z = np.random.multivariate_normal(mean=np.zeros(n_factors), cov=cov_matrix, size=n_samples)\n",
    "\n",
    "# Trichotomize Z into 0, 1, 2 categories\n",
    "Z_discrete = np.zeros_like(Z, dtype=int)\n",
    "for i in range(n_factors):\n",
    "    q1, q2 = np.percentile(Z[:, i], [33.33, 66.67])\n",
    "    Z_discrete[:, i] = np.digitize(Z[:, i], bins=[q1, q2])\n",
    "\n",
    "# Response generation rule from paper\n",
    "def simulate_response(Zd):\n",
    "    y = (\n",
    "        1.8 * (Zd[:, 0] == 1) - 1.2 * (Zd[:, 0] == 0) +\n",
    "        1.0 * (Zd[:, 2] == 1) + 0.5 * (Zd[:, 2] == 0) +\n",
    "        1.0 * (Zd[:, 4] == 1) + 1.0 * (Zd[:, 4] == 0)\n",
    "    )\n",
    "    noise = np.random.normal(0, np.std(y), size=y.shape)\n",
    "    return y + noise\n",
    "\n",
    "Y = simulate_response(Z_discrete)\n",
    "\n",
    "# One-hot encode: drop one category to avoid multicollinearity\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "X = encoder.fit_transform(Z_discrete)\n",
    "\n",
    "# Centering\n",
    "X -= X.mean(axis=0)\n",
    "Y -= Y.mean()\n",
    "\n",
    "# Group structure (each factor becomes 2 dummies after one-hot)\n",
    "group_sizes = [2] * n_factors\n",
    "group_indices = []\n",
    "start = 0\n",
    "for size in group_sizes:\n",
    "    group_indices.append(np.arange(start, start + size))\n",
    "    start += size\n",
    "\n",
    "# 2. METHODS\n",
    "\n",
    "# --- OLS Full Model ---\n",
    "def model_ols(X, Y):\n",
    "    model = LinearRegression(fit_intercept=False).fit(X, Y)\n",
    "    beta = model.coef_\n",
    "    return beta, X @ beta\n",
    "\n",
    "# --- Group LARS (greedy approximation) ---\n",
    "def group_lars(X, y, groups, max_groups=None):\n",
    "    residual = y.copy()\n",
    "    selected_groups = []\n",
    "    beta = np.zeros(X.shape[1])\n",
    "\n",
    "    for _ in range(max_groups or len(groups)):\n",
    "        correlations = [\n",
    "            np.linalg.norm(X[:, g].T @ residual) / len(g) if j not in selected_groups else -np.inf\n",
    "            for j, g in enumerate(groups)\n",
    "        ]\n",
    "        best_group = np.argmax(correlations)\n",
    "        if correlations[best_group] == -np.inf:\n",
    "            break\n",
    "        selected_groups.append(best_group)\n",
    "        X_sub = np.hstack([X[:, g] for j, g in enumerate(groups) if j in selected_groups])\n",
    "        model = LinearRegression(fit_intercept=False).fit(X_sub, y)\n",
    "        coef = model.coef_\n",
    "        index = 0\n",
    "        for j in selected_groups:\n",
    "            g = groups[j]\n",
    "            beta[g] = coef[index:index + len(g)]\n",
    "            index += len(g)\n",
    "        residual = y - X @ beta\n",
    "    return beta, X @ beta\n",
    "\n",
    "# --- Group Non-negative Garrote (approximation) ---\n",
    "def group_garrote(X, y, groups, lam=0.1):\n",
    "    ols = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "    beta_ols = ols.coef_\n",
    "    d = np.ones(len(groups))\n",
    "    for j, g in enumerate(groups):\n",
    "        group_norm = np.linalg.norm(beta_ols[g])\n",
    "        if group_norm > 0:\n",
    "            shrink = max(0, 1 - lam * len(g) / group_norm)\n",
    "            d[j] = shrink\n",
    "        else:\n",
    "            d[j] = 0\n",
    "    beta_final = np.zeros_like(beta_ols)\n",
    "    for j, g in enumerate(groups):\n",
    "        beta_final[g] = beta_ols[g] * d[j]\n",
    "    return beta_final, X @ beta_final\n",
    "\n",
    "# 3. APPLY METHODS\n",
    "beta_ols, pred_ols = model_ols(X, Y)\n",
    "beta_lars, pred_lars = group_lars(X, Y, group_indices, max_groups=5)\n",
    "beta_garrote, pred_garrote = group_garrote(X, Y, group_indices, lam=0.5)\n",
    "\n",
    "# 4. COMPARE MODELS\n",
    "mse_ols = mean_squared_error(Y, pred_ols)\n",
    "mse_lars = mean_squared_error(Y, pred_lars)\n",
    "mse_garrote = mean_squared_error(Y, pred_garrote)\n",
    "\n",
    "# Results table\n",
    "results_df = pd.DataFrame({\n",
    "    \"Method\": [\"OLS (Full)\", \"Group LARS\", \"Group Garrote\"],\n",
    "    \"MSE\": [mse_ols, mse_lars, mse_garrote]\n",
    "})\n",
    "\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "939762b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in beta_lasso after fix: 0\n",
      "NaNs in X: 0\n",
      "NaNs in Y: 0\n",
      "NaNs in beta_lasso: 0\n",
      "NaNs in pred_lasso: 0\n",
      "\n",
      "Model Comparison:\n",
      "          Method            MSE\n",
      "0    Group Lasso  2.696322e+102\n",
      "1     Group LARS   2.301095e+00\n",
      "2  Group Garrote   1.548278e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19316\\380460533.py:52: RuntimeWarning: overflow encountered in matmul\n",
      "  residual = y - X @ beta + X[:, g] @ beta[g]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19316\\380460533.py:53: RuntimeWarning: overflow encountered in matmul\n",
      "  S_j = X[:, g].T @ residual\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19316\\380460533.py:53: RuntimeWarning: invalid value encountered in matmul\n",
      "  S_j = X[:, g].T @ residual\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19316\\380460533.py:52: RuntimeWarning: invalid value encountered in matmul\n",
      "  residual = y - X @ beta + X[:, g] @ beta[g]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19316\\380460533.py:52: RuntimeWarning: invalid value encountered in add\n",
      "  residual = y - X @ beta + X[:, g] @ beta[g]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1. DATA GENERATION â€” MODEL I\n",
    "np.random.seed(0)\n",
    "n_samples = 50\n",
    "n_factors = 15\n",
    "rho = 0.5\n",
    "\n",
    "cov_matrix = rho ** np.abs(np.subtract.outer(np.arange(n_factors), np.arange(n_factors)))\n",
    "Z = np.random.multivariate_normal(mean=np.zeros(n_factors), cov=cov_matrix, size=n_samples)\n",
    "\n",
    "Z_discrete = np.zeros_like(Z, dtype=int)\n",
    "for i in range(n_factors):\n",
    "    q1, q2 = np.percentile(Z[:, i], [33.33, 66.67])\n",
    "    Z_discrete[:, i] = np.digitize(Z[:, i], bins=[q1, q2])\n",
    "\n",
    "def simulate_response(Zd):\n",
    "    y = (\n",
    "        1.8 * (Zd[:, 0] == 1) - 1.2 * (Zd[:, 0] == 0) +\n",
    "        1.0 * (Zd[:, 2] == 1) + 0.5 * (Zd[:, 2] == 0) +\n",
    "        1.0 * (Zd[:, 4] == 1) + 1.0 * (Zd[:, 4] == 0)\n",
    "    )\n",
    "    noise = np.random.normal(0, np.std(y), size=y.shape)\n",
    "    return y + noise\n",
    "\n",
    "Y = simulate_response(Z_discrete)\n",
    "\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "X = encoder.fit_transform(Z_discrete)\n",
    "X -= X.mean(axis=0)\n",
    "Y -= Y.mean()\n",
    "\n",
    "group_sizes = [2] * n_factors\n",
    "group_indices = []\n",
    "start = 0\n",
    "for size in group_sizes:\n",
    "    group_indices.append(np.arange(start, start + size))\n",
    "    start += size\n",
    "\n",
    "# 2. METHODS\n",
    "\n",
    "def group_lasso(X, y, groups, lambda_=0.5, max_iter=100, tol=1e-6):\n",
    "    beta = np.zeros(X.shape[1])\n",
    "    for iteration in range(max_iter):\n",
    "        beta_old = beta.copy()\n",
    "        for j, g in enumerate(groups):\n",
    "            # Oblicz resztÄ™ z pominiÄ™ciem bieÅ¼Ä…cej grupy\n",
    "            residual = y - X @ beta + X[:, g] @ beta[g]\n",
    "            S_j = X[:, g].T @ residual\n",
    "            norm_Sj = np.linalg.norm(S_j)\n",
    "            threshold = lambda_ * np.sqrt(len(g))\n",
    "\n",
    "            # Zgodnie z Yuan & Lin (2006) - eq. (2.4)\n",
    "            if norm_Sj <= threshold or np.isnan(norm_Sj):\n",
    "                beta[g] = 0\n",
    "            else:\n",
    "                shrinkage = 1 - threshold / norm_Sj\n",
    "                beta[g] = shrinkage * S_j\n",
    "        if np.linalg.norm(beta - beta_old) < tol:\n",
    "            break\n",
    "    return beta, X @ beta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def group_lars(X, y, groups, max_groups=None):\n",
    "    residual = y.copy()\n",
    "    selected_groups = []\n",
    "    beta = np.zeros(X.shape[1])\n",
    "    for _ in range(max_groups or len(groups)):\n",
    "        correlations = [\n",
    "            np.linalg.norm(X[:, g].T @ residual) / len(g) if j not in selected_groups else -np.inf\n",
    "            for j, g in enumerate(groups)\n",
    "        ]\n",
    "        best_group = np.argmax(correlations)\n",
    "        if correlations[best_group] == -np.inf:\n",
    "            break\n",
    "        selected_groups.append(best_group)\n",
    "        X_sub = np.hstack([X[:, g] for j, g in enumerate(groups) if j in selected_groups])\n",
    "        model = LinearRegression(fit_intercept=False).fit(X_sub, y)\n",
    "        coef = model.coef_\n",
    "        index = 0\n",
    "        for j in selected_groups:\n",
    "            g = groups[j]\n",
    "            beta[g] = coef[index:index + len(g)]\n",
    "            index += len(g)\n",
    "        residual = y - X @ beta\n",
    "    return beta, X @ beta\n",
    "\n",
    "def group_garrote(X, y, groups, lam=0.5):\n",
    "    ols = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "    beta_ols = ols.coef_\n",
    "    d = np.ones(len(groups))\n",
    "    for j, g in enumerate(groups):\n",
    "        group_norm = np.linalg.norm(beta_ols[g])\n",
    "        if group_norm > 0:\n",
    "            shrink = max(0, 1 - lam * len(g) / group_norm)\n",
    "            d[j] = shrink\n",
    "        else:\n",
    "            d[j] = 0\n",
    "    beta_final = np.zeros_like(beta_ols)\n",
    "    for j, g in enumerate(groups):\n",
    "        beta_final[g] = beta_ols[g] * d[j]\n",
    "    return beta_final, X @ beta_final\n",
    "\n",
    "# 3. APPLY METHODS\n",
    "beta_lasso, pred_lasso = group_lasso(X, Y, group_indices, lambda_=0.5)\n",
    "print(\"NaNs in beta_lasso after fix:\", np.isnan(beta_lasso).sum())\n",
    "\n",
    "\n",
    "beta_lars, pred_lars = group_lars(X, Y, group_indices, max_groups=5)\n",
    "beta_garrote, pred_garrote = group_garrote(X, Y, group_indices, lam=0.5)\n",
    "\n",
    "print(\"NaNs in X:\", np.isnan(X).sum())\n",
    "print(\"NaNs in Y:\", np.isnan(Y).sum())\n",
    "print(\"NaNs in beta_lasso:\", np.isnan(beta_lasso).sum())\n",
    "print(\"NaNs in pred_lasso:\", np.isnan(pred_lasso).sum())\n",
    "\n",
    "if np.isnan(pred_lasso).any():\n",
    "    print(\"Indexes with NaNs in pred_lasso:\", np.where(np.isnan(pred_lasso))[0])\n",
    "\n",
    "\n",
    "# 4. COMPARE MODELS\n",
    "mse_lasso = mean_squared_error(Y, pred_lasso)\n",
    "mse_lars = mean_squared_error(Y, pred_lars)\n",
    "mse_garrote = mean_squared_error(Y, pred_garrote)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Method\": [\"Group Lasso\", \"Group LARS\", \"Group Garrote\"],\n",
    "    \"MSE\": [mse_lasso, mse_lars, mse_garrote]\n",
    "})\n",
    "\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67d043c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in X: 0\n",
      "NaNs in Y: 0\n",
      "NaNs in beta_lasso: 0\n",
      "NaNs in pred_lasso: 0\n",
      "\n",
      "Model Comparison:\n",
      "          Method           MSE\n",
      "0    Group Lasso  24789.511559\n",
      "1     Group LARS      2.301095\n",
      "2  Group Garrote      0.683081\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# 1. DATA GENERATION â€” MODEL I\n",
    "np.random.seed(0)\n",
    "n_samples = 50\n",
    "n_factors = 15\n",
    "rho = 0.5\n",
    "\n",
    "cov_matrix = rho ** np.abs(np.subtract.outer(np.arange(n_factors), np.arange(n_factors)))\n",
    "Z = np.random.multivariate_normal(mean=np.zeros(n_factors), cov=cov_matrix, size=n_samples)\n",
    "\n",
    "Z_discrete = np.zeros_like(Z, dtype=int)\n",
    "for i in range(n_factors):\n",
    "    q1, q2 = np.percentile(Z[:, i], [33.33, 66.67])\n",
    "    Z_discrete[:, i] = np.digitize(Z[:, i], bins=[q1, q2])\n",
    "\n",
    "def simulate_response(Zd):\n",
    "    y = (\n",
    "        1.8 * (Zd[:, 0] == 1) - 1.2 * (Zd[:, 0] == 0) +\n",
    "        1.0 * (Zd[:, 2] == 1) + 0.5 * (Zd[:, 2] == 0) +\n",
    "        1.0 * (Zd[:, 4] == 1) + 1.0 * (Zd[:, 4] == 0)\n",
    "    )\n",
    "    noise = np.random.normal(0, np.std(y), size=y.shape)\n",
    "    return y + noise\n",
    "\n",
    "Y = simulate_response(Z_discrete)\n",
    "\n",
    "# One-hot encoding + centrowanie + normalizacja kolumn\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "X = encoder.fit_transform(Z_discrete)\n",
    "X -= X.mean(axis=0)\n",
    "X = normalize(X, axis=0)\n",
    "Y -= Y.mean()\n",
    "\n",
    "# Grupy\n",
    "group_sizes = [2] * n_factors\n",
    "group_indices = []\n",
    "start = 0\n",
    "for size in group_sizes:\n",
    "    group_indices.append(np.arange(start, start + size))\n",
    "    start += size\n",
    "\n",
    "# 2. METHODS\n",
    "\n",
    "def group_lasso(X, y, groups, lambda_=0.05, max_iter=100, tol=1e-6):\n",
    "    beta = np.zeros(X.shape[1])\n",
    "    for iteration in range(max_iter):\n",
    "        beta_old = beta.copy()\n",
    "        for j, g in enumerate(groups):\n",
    "            residual = y - X @ beta + X[:, g] @ beta[g]\n",
    "            S_j = X[:, g].T @ residual\n",
    "            norm_Sj = np.linalg.norm(S_j)\n",
    "            threshold = lambda_ * np.sqrt(len(g))\n",
    "            if norm_Sj <= threshold or np.isnan(norm_Sj):\n",
    "                beta[g] = 0\n",
    "            else:\n",
    "                shrinkage = 1 - threshold / norm_Sj\n",
    "            beta_g_update = shrinkage * S_j\n",
    "            if np.linalg.norm(beta_g_update) > 1e3:  # limit stabilizujÄ…cy\n",
    "                beta[g] = 0\n",
    "            else:\n",
    "                beta[g] = beta_g_update\n",
    "\n",
    "        if np.linalg.norm(beta - beta_old) < tol:\n",
    "            break\n",
    "    return beta, X @ beta\n",
    "\n",
    "def group_lars(X, y, groups, max_groups=None):\n",
    "    residual = y.copy()\n",
    "    selected_groups = []\n",
    "    beta = np.zeros(X.shape[1])\n",
    "    for _ in range(max_groups or len(groups)):\n",
    "        correlations = [\n",
    "            np.linalg.norm(X[:, g].T @ residual) / len(g) if j not in selected_groups else -np.inf\n",
    "            for j, g in enumerate(groups)\n",
    "        ]\n",
    "        best_group = np.argmax(correlations)\n",
    "        if correlations[best_group] == -np.inf:\n",
    "            break\n",
    "        selected_groups.append(best_group)\n",
    "        X_sub = np.hstack([X[:, g] for j, g in enumerate(groups) if j in selected_groups])\n",
    "        model = LinearRegression(fit_intercept=False).fit(X_sub, y)\n",
    "        coef = model.coef_\n",
    "        index = 0\n",
    "        for j in selected_groups:\n",
    "            g = groups[j]\n",
    "            beta[g] = coef[index:index + len(g)]\n",
    "            index += len(g)\n",
    "        residual = y - X @ beta\n",
    "    return beta, X @ beta\n",
    "\n",
    "def group_garrote(X, y, groups, lam=0.5):\n",
    "    ols = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "    beta_ols = ols.coef_\n",
    "    d = np.ones(len(groups))\n",
    "    for j, g in enumerate(groups):\n",
    "        group_norm = np.linalg.norm(beta_ols[g])\n",
    "        if group_norm > 0:\n",
    "            shrink = max(0, 1 - lam * len(g) / group_norm)\n",
    "            d[j] = shrink\n",
    "        else:\n",
    "            d[j] = 0\n",
    "    beta_final = np.zeros_like(beta_ols)\n",
    "    for j, g in enumerate(groups):\n",
    "        beta_final[g] = beta_ols[g] * d[j]\n",
    "    return beta_final, X @ beta_final\n",
    "\n",
    "# 3. APPLY METHODS\n",
    "beta_lasso, pred_lasso = group_lasso(X, Y, group_indices, lambda_=0.05)\n",
    "beta_lars, pred_lars = group_lars(X, Y, group_indices, max_groups=5)\n",
    "beta_garrote, pred_garrote = group_garrote(X, Y, group_indices, lam=0.5)\n",
    "\n",
    "# 4. CHECK NaNs\n",
    "print(\"NaNs in X:\", np.isnan(X).sum())\n",
    "print(\"NaNs in Y:\", np.isnan(Y).sum())\n",
    "print(\"NaNs in beta_lasso:\", np.isnan(beta_lasso).sum())\n",
    "print(\"NaNs in pred_lasso:\", np.isnan(pred_lasso).sum())\n",
    "\n",
    "# 5. COMPARE MODELS\n",
    "mse_lasso = mean_squared_error(Y, pred_lasso)\n",
    "mse_lars = mean_squared_error(Y, pred_lars)\n",
    "mse_garrote = mean_squared_error(Y, pred_garrote)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Method\": [\"Group Lasso\", \"Group LARS\", \"Group Garrote\"],\n",
    "    \"MSE\": [mse_lasso, mse_lars, mse_garrote]\n",
    "})\n",
    "\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e92ea553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing cross-validation for group_lasso...\n",
      "Î» = 0.0100 | CV MSE = 124.8265\n",
      "Î» = 0.0135 | CV MSE = 119.7698\n",
      "Î» = 0.0183 | CV MSE = 113.1176\n",
      "Î» = 0.0248 | CV MSE = 104.4650\n",
      "Î» = 0.0336 | CV MSE = 93.3944\n",
      "Î» = 0.0455 | CV MSE = 79.5809\n",
      "Î» = 0.0616 | CV MSE = 63.0123\n",
      "Î» = 0.0834 | CV MSE = 44.3725\n",
      "Î» = 0.1129 | CV MSE = 25.5574\n",
      "Î» = 0.1528 | CV MSE = 11.1446\n",
      "Î» = 0.2069 | CV MSE = 4.5060\n",
      "Î» = 0.2801 | CV MSE = 3.2148\n",
      "Î» = 0.3793 | CV MSE = 2.9620\n",
      "Î» = 0.5135 | CV MSE = 2.7088\n",
      "Î» = 0.6952 | CV MSE = 2.5939\n",
      "Î» = 0.9412 | CV MSE = 2.5447\n",
      "Î» = 1.2743 | CV MSE = 2.5458\n",
      "Î» = 1.7252 | CV MSE = 2.5960\n",
      "Î» = 2.3357 | CV MSE = 2.7034\n",
      "Î» = 3.1623 | CV MSE = 2.7813\n",
      "\n",
      "âœ… Best lambda: 0.9412 | CV MSE: 2.5447\n",
      "\n",
      "ðŸ“Š Final Group Lasso MSE on full data: 1.1549\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 1. DATA GENERATION â€” MODEL I\n",
    "np.random.seed(0)\n",
    "n_samples = 50\n",
    "n_factors = 15\n",
    "rho = 0.5\n",
    "\n",
    "cov_matrix = rho ** np.abs(np.subtract.outer(np.arange(n_factors), np.arange(n_factors)))\n",
    "Z = np.random.multivariate_normal(mean=np.zeros(n_factors), cov=cov_matrix, size=n_samples)\n",
    "\n",
    "Z_discrete = np.zeros_like(Z, dtype=int)\n",
    "for i in range(n_factors):\n",
    "    q1, q2 = np.percentile(Z[:, i], [33.33, 66.67])\n",
    "    Z_discrete[:, i] = np.digitize(Z[:, i], bins=[q1, q2])\n",
    "\n",
    "def simulate_response(Zd):\n",
    "    y = (\n",
    "        1.8 * (Zd[:, 0] == 1) - 1.2 * (Zd[:, 0] == 0) +\n",
    "        1.0 * (Zd[:, 2] == 1) + 0.5 * (Zd[:, 2] == 0) +\n",
    "        1.0 * (Zd[:, 4] == 1) + 1.0 * (Zd[:, 4] == 0)\n",
    "    )\n",
    "    noise = np.random.normal(0, np.std(y), size=y.shape)\n",
    "    return y + noise\n",
    "\n",
    "Y = simulate_response(Z_discrete)\n",
    "Y -= Y.mean()\n",
    "\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "X = encoder.fit_transform(Z_discrete)\n",
    "X -= X.mean(axis=0)\n",
    "X /= np.linalg.norm(X, axis=0)  # normalizacja kolumn\n",
    "\n",
    "group_sizes = [2] * n_factors\n",
    "group_indices = []\n",
    "start = 0\n",
    "for size in group_sizes:\n",
    "    group_indices.append(np.arange(start, start + size))\n",
    "    start += size\n",
    "\n",
    "# 2. YOUR ORIGINAL GROUP LASSO\n",
    "def group_lasso(X, y, groups, lambda_, max_iter=100, tol=1e-6):\n",
    "    beta = np.zeros(X.shape[1])\n",
    "    for _ in range(max_iter):\n",
    "        beta_old = beta.copy()\n",
    "        for j, g in enumerate(groups):\n",
    "            residual = y - X @ beta + X[:, g] @ beta[g]\n",
    "            S_j = X[:, g].T @ residual\n",
    "            norm_Sj = np.linalg.norm(S_j)\n",
    "            threshold = lambda_ * np.sqrt(len(g))\n",
    "            if norm_Sj <= threshold or np.isnan(norm_Sj):\n",
    "                beta[g] = 0\n",
    "            else:\n",
    "                shrinkage = 1 - threshold / norm_Sj\n",
    "                beta_g_update = shrinkage * S_j\n",
    "                if np.linalg.norm(beta_g_update) > 1e3:\n",
    "                    beta[g] = 0\n",
    "                else:\n",
    "                    beta[g] = beta_g_update\n",
    "        if np.linalg.norm(beta - beta_old) < tol:\n",
    "            break\n",
    "    return beta, X @ beta\n",
    "\n",
    "# 3. CROSS-VALIDATION FOR LAMBDA SELECTION\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lambdas = np.logspace(-2, 0.5, 20)  # od 0.01 do ~3.16\n",
    "\n",
    "best_lambda = None\n",
    "best_mse = np.inf\n",
    "\n",
    "print(\"Performing cross-validation for group_lasso...\")\n",
    "\n",
    "for lam in lambdas:\n",
    "    mses = []\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "\n",
    "        beta, _ = group_lasso(X_train, y_train, group_indices, lambda_=lam)\n",
    "        y_pred = X_test @ beta\n",
    "        if np.any(np.isnan(y_pred)):\n",
    "            mse = np.inf\n",
    "        else:\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "        mses.append(mse)\n",
    "\n",
    "    mean_mse = np.mean(mses)\n",
    "    print(f\"Î» = {lam:.4f} | CV MSE = {mean_mse:.4f}\")\n",
    "    if mean_mse < best_mse:\n",
    "        best_mse = mean_mse\n",
    "        best_lambda = lam\n",
    "\n",
    "print(f\"\\nâœ… Best lambda: {best_lambda:.4f} | CV MSE: {best_mse:.4f}\")\n",
    "\n",
    "# 4. FIT FINAL MODEL\n",
    "beta_final, pred_final = group_lasso(X, Y, group_indices, lambda_=best_lambda)\n",
    "mse_final = mean_squared_error(Y, pred_final)\n",
    "\n",
    "print(f\"\\nðŸ“Š Final Group Lasso MSE on full data: {mse_final:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
